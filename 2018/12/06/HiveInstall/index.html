
<!DOCTYPE html>
<html lang="zh-CN" class="loading">
<head>
    <meta charset="UTF-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, minimum-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <title>抱着西瓜砸地球的博客</title>

    <meta name="apple-mobile-web-app-capable" content="yes" />
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="google" content="notranslate" />
    <meta name="keywords" content="Blog,"> 
    <meta name="description" content="OpenStack 是一个云操作系统，通过数据中心可控制大型的计算、存储、网络等资源池。所有的管理通过前端界面管理员就可以完成，同样也可以通过 web 接口让最终用户部署资源。
参考文档: 

官方,"> 
    <meta name="author" content="YongJie-Xie"> 
    <link rel="alternative" href="atom.xml" title="抱着西瓜砸地球的博客" type="application/atom+xml"> 
    <link rel="icon" href="/img/favicon.png"> 
    <link rel="stylesheet" href="//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.css">
    <link rel="stylesheet" href="/css/diaspora.css">
</head>

<body class="loading">
    <div id="loader"></div>
    <div id="single">
    <div id="top" style="display: block;">
    <div class="bar" style="width: 0;"></div>
    <a class="icon-home image-icon" href="javascript:;"></a>
    <div title="播放/暂停" class="icon-play"></div>
    <h3 class="subtitle">Hive 安装</h3>
    <div class="social">
        <!--<div class="like-icon">-->
            <!--<a href="javascript:;" class="likeThis active"><span class="icon-like"></span><span class="count">76</span></a>-->
        <!--</div>-->
        <div>
            <div class="share">
                <a title="获取二维码" class="icon-scan" href="javascript:;"></a>
            </div>
            <div id="qr"></div>
        </div>
    </div>
    <div class="scrollbar"></div>
</div>
    <div class="section">
        <div class="article">
    <div class='main'>
        <h1 class="title">Hive 安装</h1>
        <div class="stuff">
            <span>十二月 06, 2018</span>
            
  <ul class="post-tags-list"><li class="post-tags-list-item"><a class="post-tags-list-link" href="/tags/CentOS/">CentOS</a></li><li class="post-tags-list-item"><a class="post-tags-list-link" href="/tags/Hadoop/">Hadoop</a></li><li class="post-tags-list-item"><a class="post-tags-list-link" href="/tags/Hive/">Hive</a></li><li class="post-tags-list-item"><a class="post-tags-list-link" href="/tags/Java/">Java</a></li><li class="post-tags-list-item"><a class="post-tags-list-link" href="/tags/VMware/">VMware</a></li></ul>


        </div>
        <div class="content markdown">
            <p>Hive 是基于 Hadoop 的一个数据仓库工具, 可以将结构化的数据文件映射为一张数据库表, 并提供简单的 Sql 查询功能, 可以将 Sql 语句转换为 MapReduce 任务进行运行</p>
<p>说明: Hive 是基于 Hadoop 安装的, 所以必须符合以下条件</p>
<ol>
<li>拥有已安装 Hadoop 的服务器集群</li>
<li>确保 Hadoop 集群正常运行 (启动 Hive 或 使用 Hadoop 命令时需要)</li>
<li>拥有已安装 Mysql 或 Mssql 的服务器 (本安装教程使用的数据库为 Mysql-5.6)</li>
</ol>
<h2 id="一、准备工作"><a href="#一、准备工作" class="headerlink" title="一、准备工作"></a>一、准备工作</h2><h3 id="0-配置要求"><a href="#0-配置要求" class="headerlink" title="0. 配置要求"></a>0. 配置要求</h3><h4 id="a-物理机"><a href="#a-物理机" class="headerlink" title="a) 物理机"></a>a) 物理机</h4><ul>
<li>处理器: 无要求</li>
<li>内存: 至少4G (建议8G或以上)</li>
<li>硬盘: 至少30G (建议50G或以上)</li>
<li>网卡: 可以上网即可</li>
</ul>
<h4 id="b-虚拟机"><a href="#b-虚拟机" class="headerlink" title="b) 虚拟机"></a>b) 虚拟机</h4><ul>
<li>数量: 至少3台 (1台Master、2台Worker)</li>
<li>处理器: 至少1个1核 (建议2个1核或以上)</li>
<li>内存: 至少512M (建议1G或以上)</li>
<li>硬盘: 至少10G (建议20G或以上)</li>
<li>网卡: 使用NAT模式即可</li>
</ul>
<h4 id="c-数据库"><a href="#c-数据库" class="headerlink" title="c) 数据库"></a>c) 数据库</h4><ul>
<li>数据库选择: Mysql 或 Mssql</li>
<li>权限要求: 至少拥有某个数据库的管理权</li>
</ul>
<p><strong>本安装教程使用的虚拟机配置如下</strong><br>Hadoop - Master:<br>内存(1G), 处理器(单核), 硬盘(20G), 网络(NAT - 192.168.80.100/24 - hadoop.master)<br>Hadoop - Worker1<br>内存(1G), 处理器(单核), 硬盘(20G), 网络(NAT - 192.168.80.110/24 - hadoop.worker1)<br>Hadoop - Worker2<br>内存(1G), 处理器(单核), 硬盘(20G), 网络(NAT - 192.168.80.111/24 - hadoop.worker2)<br>Mysql - root/123456<br>内存(1G), 处理器(单核), 硬盘(20G), 网络(NAT - 192.168.80.90/24)</p>
<h3 id="1-软件工具下载"><a href="#1-软件工具下载" class="headerlink" title="1. 软件工具下载"></a>1. 软件工具下载</h3><ul>
<li><a href="https://www-us.apache.org/dist/hive/hive-3.1.1/apache-hive-3.1.1-bin.tar.gz" target="_blank" rel="noopener">Apache Hive 3.1.1</a></li>
<li><a href="http://central.maven.org/maven2/mysql/mysql-connector-java/5.1.47/mysql-connector-java-5.1.47.jar" target="_blank" rel="noopener">Mysql-5.1.47</a> - (本安装教程的驱动包)</li>
<li><a href="http://central.maven.org/maven2/mysql/mysql-connector-java/8.0.13/mysql-connector-java-8.0.13.jar" target="_blank" rel="noopener">Mysql-8.0.13</a></li>
<li><a href="http://central.maven.org/maven2/com/microsoft/sqlserver/mssql-jdbc/7.1.3.jre11-preview/mssql-jdbc-7.1.3.jre11-preview.jar" target="_blank" rel="noopener">Mssql-7.1.3</a></li>
<li><a href="http://www.netsarang.com/download/down_form.html?code=622" target="_blank" rel="noopener">Xshell 6</a> --&gt; 个人免费, License type 选择 Home and school use, 邮箱获取下载链接</li>
<li><a href="http://www.netsarang.com/download/down_form.html?code=623" target="_blank" rel="noopener">Xftp 6</a> --&gt; 同上</li>
</ul>
<h3 id="2-基础环境搭建"><a href="#2-基础环境搭建" class="headerlink" title="2. 基础环境搭建"></a>2. 基础环境搭建</h3><h4 id="a-安装-Hadoop-的-CentOS-7-服务器集群"><a href="#a-安装-Hadoop-的-CentOS-7-服务器集群" class="headerlink" title="a) 安装 Hadoop 的 CentOS 7 服务器集群"></a>a) 安装 Hadoop 的 CentOS 7 服务器集群</h4><p>参考<a href="https://yongjie-xie.github.io/2018/10/10/HadoopInstall">这里</a></p>
<h4 id="b-安装-Docker-容器-CentOS-Ubuntu-lt-使用容器安装-Mysql-或-Mssql-方便高效"><a href="#b-安装-Docker-容器-CentOS-Ubuntu-lt-使用容器安装-Mysql-或-Mssql-方便高效" class="headerlink" title="b) 安装 Docker 容器 (CentOS / Ubuntu) &lt;-- 使用容器安装 Mysql 或 Mssql 方便高效"></a>b) 安装 Docker 容器 (CentOS / Ubuntu) &lt;-- 使用容器安装 Mysql 或 Mssql 方便高效</h4><p>参考<a href="https://yongjie-xie.github.io/2018/12/6/DockerInstall">这里</a></p>
<h4 id="c-安装-Xshell-6-和-Xftp-6-物理机"><a href="#c-安装-Xshell-6-和-Xftp-6-物理机" class="headerlink" title="c) 安装 Xshell 6 和 Xftp 6 (物理机)"></a>c) 安装 Xshell 6 和 Xftp 6 (物理机)</h4><p>过程略</p>
<h2 id="二、安装-Hive"><a href="#二、安装-Hive" class="headerlink" title="二、安装 Hive"></a>二、安装 Hive</h2><p><strong><em>注意: 必须在 Master 的 hadoop 用户下执行, 无需在 Worker1、Worker2 服务器中执行</em></strong></p>
<h3 id="1-Hive-安装文件下载和解压"><a href="#1-Hive-安装文件下载和解压" class="headerlink" title="1. Hive 安装文件下载和解压"></a>1. Hive 安装文件下载和解压</h3><p><strong><em>注意: Hive 放在 home 目录下, 也就是 /home/hadoop/ 目录</em></strong><br>命令:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span></span><br><span class="line">wget https://www-us.apache.org/dist/hive/hive-3.1.1/apache-hive-3.1.1-bin.tar.gz</span><br><span class="line">tar zxf apache-hive-3.1.1-bin.tar.gz</span><br><span class="line">mv apache-hive-3.1.1-bin hive</span><br></pre></td></tr></table></figure></p>
<p>结果:<br><figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop ~]<span class="comment"># su hadoop</span></span><br><span class="line">[hadoop@hadoop root]$ cd</span><br><span class="line">[hadoop@hadoop ~]$ wget <span class="symbol">https:</span>/<span class="regexp">/www-us.apache.org/dist</span><span class="regexp">/hive/hive</span>-<span class="number">3.1</span>.<span class="number">1</span>/apache-hive-<span class="number">3.1</span>.<span class="number">1</span>-bin.tar.gz</span><br><span class="line">--<span class="number">2018</span>-<span class="number">12</span>-<span class="number">06</span> <span class="number">12</span><span class="symbol">:</span><span class="number">59</span><span class="symbol">:</span><span class="number">23</span>--  <span class="symbol">https:</span>/<span class="regexp">/www-us.apache.org/dist</span><span class="regexp">/hive/hive</span>-<span class="number">3.1</span>.<span class="number">1</span>/apache-hive-<span class="number">3.1</span>.<span class="number">1</span>-bin.tar.gz</span><br><span class="line">Resolving www-us.apache.org (www-us.apache.org)... <span class="number">40.79</span>.<span class="number">78.1</span></span><br><span class="line">Connecting to www-us.apache.org (www-us.apache.org)<span class="params">|40.79.78.1|</span><span class="symbol">:</span><span class="number">443</span>... connected.</span><br><span class="line">HTTP request sent, awaiting response... <span class="number">200</span> OK</span><br><span class="line"><span class="symbol">Length:</span> <span class="number">280944629</span> (<span class="number">268</span>M) [application/x-gzip]</span><br><span class="line">Saving <span class="symbol">to:</span> ‘apache-hive-<span class="number">3.1</span>.<span class="number">1</span>-bin.tar.gz’</span><br><span class="line"></span><br><span class="line"><span class="number">100</span><span class="string">%[==================================================================================&gt;]</span> <span class="number">280</span>,<span class="number">944</span>,<span class="number">629</span> <span class="number">11.0</span>MB/s   <span class="keyword">in</span> <span class="number">29</span>s    </span><br><span class="line"></span><br><span class="line"><span class="number">2018</span>-<span class="number">12</span>-<span class="number">06</span> <span class="number">12</span><span class="symbol">:</span><span class="number">59</span><span class="symbol">:</span><span class="number">59</span> (<span class="number">9.18</span> MB/s) - ‘apache-hive-<span class="number">3.1</span>.<span class="number">1</span>-bin.tar.gz’ saved [<span class="number">280944629</span>/<span class="number">280944629</span>]</span><br><span class="line"></span><br><span class="line">[hadoop@hadoop ~]$ tar zxf apache-hive-<span class="number">3.1</span>.<span class="number">1</span>-bin.tar.gz</span><br><span class="line">[hadoop@hadoop ~]$ mv apache-hive-<span class="number">3.1</span>.<span class="number">1</span>-bin hive</span><br></pre></td></tr></table></figure></p>
<h3 id="2-驱动包部署"><a href="#2-驱动包部署" class="headerlink" title="2. 驱动包部署"></a>2. 驱动包部署</h3><p>命令:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> ~/hive/lib/</span><br><span class="line">wget http://central.maven.org/maven2/mysql/mysql-connector-java/5.1.47/mysql-connector-java-5.1.47.jar</span><br></pre></td></tr></table></figure></p>
<p>结果:<br><figure class="highlight groovy"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">[hadoop<span class="meta">@hadoop</span> conf]$ cd <span class="regexp">~/hive/</span>lib/</span><br><span class="line">[hadoop<span class="meta">@hadoop</span> lib]$ wget <span class="string">http:</span><span class="comment">//central.maven.org/maven2/mysql/mysql-connector-java/5.1.47/mysql-connector-java-5.1.47.jar</span></span><br><span class="line">-<span class="number">-2018</span><span class="number">-12</span><span class="number">-06</span> <span class="number">15</span>:<span class="number">45</span>:<span class="number">45</span>--  <span class="string">http:</span><span class="comment">//central.maven.org/maven2/mysql/mysql-connector-java/5.1.47/mysql-connector-java-5.1.47.jar</span></span><br><span class="line">Resolving central.maven.org (central.maven.org)... <span class="number">151.101</span><span class="number">.24</span><span class="number">.209</span></span><br><span class="line">Connecting to central.maven.org (central.maven.org)|<span class="number">151.101</span><span class="number">.24</span><span class="number">.209</span>|:<span class="number">80.</span>.. connected.</span><br><span class="line">HTTP request sent, awaiting response... <span class="number">200</span> OK</span><br><span class="line"><span class="string">Length:</span> <span class="number">1007502</span> (<span class="number">984</span>K) [application/java-archive]</span><br><span class="line">Saving <span class="string">to:</span> ‘mysql-connector-java<span class="number">-5.1</span><span class="number">.47</span>.jar’</span><br><span class="line"></span><br><span class="line"><span class="number">100</span>%[==================================================================================&gt;] <span class="number">1</span>,<span class="number">007</span>,<span class="number">502</span>    <span class="number">679</span>KB/s   <span class="keyword">in</span> <span class="number">1.4</span>s   </span><br><span class="line"></span><br><span class="line"><span class="number">2018</span><span class="number">-12</span><span class="number">-06</span> <span class="number">15</span>:<span class="number">45</span>:<span class="number">52</span> (<span class="number">679</span> KB<span class="regexp">/s) - ‘mysql-connector-java-5.1.47.jar’ saved [1007502/</span><span class="number">1007502</span>]</span><br></pre></td></tr></table></figure></p>
<h2 id="三、配置-Hive"><a href="#三、配置-Hive" class="headerlink" title="三、配置 Hive"></a>三、配置 Hive</h2><p><strong><em>注意: 必须在 Master 的 hadoop 用户下执行, 无需在 Worker1、Worker2 服务器中执行</em></strong></p>
<h3 id="1-hive-site-xml"><a href="#1-hive-site-xml" class="headerlink" title="1. hive-site.xml"></a>1. hive-site.xml</h3><p>命令:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">cp ~/hive/conf/hive-default.xml.template ~/hive/conf/hive-site.xml</span><br><span class="line">sed -i <span class="string">"s#\$&#123;system:java.io.tmpdir&#125;#/home/hadoop/hive/tmp#g"</span> ~/hive/conf/hive-site.xml</span><br><span class="line">sed -i <span class="string">"s#\$&#123;system:user.name&#125;#hadoop#g"</span> ~/hive/conf/hive-site.xml</span><br><span class="line">sed -i <span class="string">"s@&amp;#8;@ @g"</span> ~/hive/conf/hive-site.xml</span><br><span class="line">sed -i <span class="string">"s#jdbc:derby:;databaseName=metastore_db;create=true#ConnectionURL#g"</span> ~/hive/conf/hive-site.xml</span><br><span class="line">sed -i <span class="string">"s#&lt;value&gt;org.apache.derby.jdbc.EmbeddedDriver#&lt;value&gt;DriverName#g"</span> ~/hive/conf/hive-site.xml</span><br><span class="line">sed -i <span class="string">"s#&lt;value&gt;APP#&lt;value&gt;Username#g"</span> ~/hive/conf/hive-site.xml</span><br><span class="line">sed -i <span class="string">"s#&lt;value&gt;mine#&lt;value&gt;Password#g"</span> ~/hive/conf/hive-site.xml</span><br><span class="line"></span><br><span class="line"><span class="comment"># 请修改上述命令中的 [ConnectionURL, DriverName, Username, Password], 如下所示</span></span><br><span class="line"><span class="comment"># ConnectionURL:</span></span><br><span class="line"><span class="comment"># mysql - jdbc:mysql://localhost:3306/hive?createDatabaseIfNotExist=true</span></span><br><span class="line"><span class="comment"># mssql - jdbc:sqlserver://localhost:1433;databaseName=hive;create=true</span></span><br><span class="line"><span class="comment"># DriverName:</span></span><br><span class="line"><span class="comment"># mysql - com.mysql.jdbc.Driver</span></span><br><span class="line"><span class="comment"># mssql - com.microsoft.sqlserver.jdbc.SQLServerDriver</span></span><br><span class="line"><span class="comment"># Username, Password 替换为正确的用户名和密码</span></span><br></pre></td></tr></table></figure></p>
<p>结果:<br><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hadoop conf]$ cp ~/hive/conf/hive-default<span class="selector-class">.xml</span><span class="selector-class">.template</span> ~/hive/conf/hive-site.xml</span><br><span class="line">[hadoop@hadoop conf]$ sed -<span class="selector-tag">i</span> <span class="string">"s#\$&#123;system:java.io.tmpdir&#125;#/home/hadoop/hive/tmp#g"</span> ~/hive/conf/hive-site.xml</span><br><span class="line">[hadoop@hadoop conf]$ sed -<span class="selector-tag">i</span> <span class="string">"s#\$&#123;system:user.name&#125;#hadoop#g"</span> ~/hive/conf/hive-site.xml</span><br><span class="line">[hadoop@hadoop conf]$ sed -<span class="selector-tag">i</span> <span class="string">"s#jdbc:derby:;databaseName=metastore_db;create=true#jdbc:mysql://192.168.80.90:3306/hive?createDatabaseIfNotExist=true#g"</span> ~/hive/conf/hive-site.xml</span><br><span class="line">[hadoop@hadoop conf]$ sed -<span class="selector-tag">i</span> <span class="string">"s#&lt;value&gt;org.apache.derby.jdbc.EmbeddedDriver#&lt;value&gt;com.mysql.jdbc.Driver#g"</span> ~/hive/conf/hive-site.xml</span><br><span class="line">[hadoop@hadoop conf]$ sed -<span class="selector-tag">i</span> <span class="string">"s#&lt;value&gt;APP#&lt;value&gt;root#g"</span> ~/hive/conf/hive-site.xml</span><br><span class="line">[hadoop@hadoop conf]$ sed -<span class="selector-tag">i</span> <span class="string">"s#&lt;value&gt;mine#&lt;value&gt;123456#g"</span> ~/hive/conf/hive-site.xml</span><br></pre></td></tr></table></figure></p>
<h3 id="2-hive-env-sh"><a href="#2-hive-env-sh" class="headerlink" title="2. hive-env.sh"></a>2. hive-env.sh</h3><p>命令:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">cp ~/hive/conf/hive-env.sh.template ~/hive/conf/hive-env.sh</span><br><span class="line">sed -i <span class="string">"s@# HADOOP_HOME=\$&#123;bin&#125;/../../hadoop@export HADOOP_HOME=<span class="variable">$HADOOP_HOME</span>@g"</span> ~/hive/conf/hive-env.sh</span><br><span class="line">sed -i <span class="string">"s@# export HIVE_CONF_DIR=@export HIVE_CONF_DIR=<span class="variable">$HIVE_CONF_DIR</span>@g"</span> ~/hive/conf/hive-env.sh</span><br><span class="line">sed -i <span class="string">"s@# export HIVE_AUX_JARS_PATH=@export HIVE_AUX_JARS_PATH=<span class="variable">$HIVE_HOME</span>/lib@g"</span> ~/hive/conf/hive-env.sh</span><br><span class="line"></span><br><span class="line"><span class="comment"># 执行前请确保环境变量设置正确, 设置环境变量请参考本节第3点</span></span><br><span class="line"><span class="comment"># $HADOOP_HOME $HIVE_HOME $HIVE_CONF_DIR</span></span><br></pre></td></tr></table></figure></p>
<p>结果:<br><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hadoop <span class="keyword">conf</span>]$ <span class="keyword">cp</span> ~/hive/<span class="keyword">conf</span>/hive-env.<span class="keyword">sh</span>.template ~/hive/<span class="keyword">conf</span>/hive-env.<span class="keyword">sh</span></span><br><span class="line">[hadoop@hadoop <span class="keyword">conf</span>]$ sed -i <span class="string">"s@# HADOOP_HOME=\$&#123;bin&#125;/../../hadoop@export HADOOP_HOME=$HADOOP_HOME@g"</span> ~/hive/<span class="keyword">conf</span>/hive-env.<span class="keyword">sh</span></span><br><span class="line">[hadoop@hadoop <span class="keyword">conf</span>]$ sed -i <span class="string">"s@# export HIVE_CONF_DIR=@export JAVA_HOME=$HIVE_CONF_DIR@g"</span> ~/hive/<span class="keyword">conf</span>/hive-env.<span class="keyword">sh</span></span><br><span class="line">[hadoop@hadoop <span class="keyword">conf</span>]$ sed -i <span class="string">"s@# export HIVE_AUX_JARS_PATH=@export HIVE_AUX_JARS_PATH=$HIVE_HOME/lib@g"</span> ~/hive/<span class="keyword">conf</span>/hive-env.<span class="keyword">sh</span></span><br><span class="line">[hadoop@hadoop <span class="keyword">conf</span>]$ <span class="keyword">cat</span>  ~/hive/<span class="keyword">conf</span>/hive-env.<span class="keyword">sh</span></span><br><span class="line"># Licensed <span class="keyword">to</span> the Apache Software Foundation (ASF) under one</span><br><span class="line"># <span class="built_in">or</span> more contributor license agreements.  See the NOTICE <span class="keyword">file</span></span><br><span class="line">...</span><br><span class="line"></span><br><span class="line"># Set HADOOP_HOME <span class="keyword">to</span> point <span class="keyword">to</span> <span class="keyword">a</span> specific hadoop install directory</span><br><span class="line">export HADOOP_HOME=/home/hadoop/hadoop</span><br><span class="line"></span><br><span class="line"># Hive Configuration Directory can <span class="keyword">be</span> controlled by:</span><br><span class="line">export HIVE_CONF_DIR=/home/hadoop/hive/<span class="keyword">conf</span></span><br><span class="line"></span><br><span class="line"># Folder containing extra libraries required <span class="keyword">for</span> hive compilation/execution can <span class="keyword">be</span> controlled by:</span><br><span class="line">export HIVE_AUX_JARS_PATH=/home/hadoop/hive/lib</span><br></pre></td></tr></table></figure></p>
<h3 id="3-环境变量-bashrc"><a href="#3-环境变量-bashrc" class="headerlink" title="3. 环境变量 .bashrc"></a>3. 环境变量 .bashrc</h3><p>命令:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">vim ~/.bashrc</span><br><span class="line">cat ~/.bashrc</span><br><span class="line"><span class="built_in">source</span> ~/.bashrc</span><br></pre></td></tr></table></figure></p>
<p>结果:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hadoop ~]$ vim ~/.bashrc </span><br><span class="line">[hadoop@hadoop ~]$ cat ~/.bashrc </span><br><span class="line"><span class="comment"># .bashrc</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Source global definitions</span></span><br><span class="line"><span class="keyword">if</span> [ -f /etc/bashrc ]; <span class="keyword">then</span></span><br><span class="line">    . /etc/bashrc</span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Uncomment the following line if you don't like systemctl's auto-paging feature:</span></span><br><span class="line"><span class="comment"># export SYSTEMD_PAGER=</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># User specific aliases and functions</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Hadoop Env</span></span><br><span class="line"><span class="built_in">export</span> HADOOP_HOME=/home/hadoop/hadoop</span><br><span class="line"><span class="built_in">export</span> HADOOP_INSTALL=<span class="variable">$HADOOP_HOME</span></span><br><span class="line"><span class="built_in">export</span> HADOOP_MAPRED_HOME=<span class="variable">$HADOOP_HOME</span></span><br><span class="line"><span class="built_in">export</span> HADOOP_COMMON_HOME=<span class="variable">$HADOOP_HOME</span></span><br><span class="line"><span class="built_in">export</span> HADOOP_HDFS_HOME=<span class="variable">$HADOOP_HOME</span></span><br><span class="line"><span class="built_in">export</span> YARN_HOME=<span class="variable">$HADOOP_HOME</span></span><br><span class="line"><span class="built_in">export</span> HADOOP_COMMON_LIB_NATIVE_DIR=<span class="variable">$HADOOP_HOME</span>/lib/native</span><br><span class="line"><span class="built_in">export</span> HIVE_HOME=/home/hadoop/hive // 增加</span><br><span class="line"><span class="built_in">export</span> HIVE_CONF_DIR=<span class="variable">$HIVE_HOME</span>/conf // 增加</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$HADOOP_HOME</span>/sbin:<span class="variable">$HADOOP_HOME</span>/bin:<span class="variable">$HIVE_HOME</span>/bin // 修改</span><br><span class="line">[hadoop@hadoop ~]$ <span class="built_in">source</span> ~/.bashrc</span><br></pre></td></tr></table></figure></p>
<h3 id="4-创建必须目录-请确保-Hadoop-正常运行"><a href="#4-创建必须目录-请确保-Hadoop-正常运行" class="headerlink" title="4. 创建必须目录 (请确保 Hadoop 正常运行)"></a>4. 创建必须目录 (请确保 Hadoop 正常运行)</h3><p>命令:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">jps</span><br><span class="line">hadoop fs -mkdir -p /user/hive/warehouse</span><br><span class="line">hadoop fs -chmod 777 /user/hive/warehouse</span><br><span class="line">hadoop fs -mkdir -p /tmp/hive</span><br><span class="line">hadoop fs -chmod 777 /tmp/hive</span><br><span class="line">hadoop fs -ls /user/hive/</span><br><span class="line">hadoop fs -ls /tmp/</span><br><span class="line">[hadoop@hadoop hive]$ mkdir -p ~/hive/tmp</span><br></pre></td></tr></table></figure></p>
<p>结果:<br><figure class="highlight groovy"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">[hadoop<span class="meta">@hadoop</span> hive]$ jps</span><br><span class="line"><span class="number">2036</span> ResourceManager</span><br><span class="line"><span class="number">2344</span> Jps</span><br><span class="line"><span class="number">1785</span> SecondaryNameNode</span><br><span class="line"><span class="number">1597</span> NameNode</span><br><span class="line">[hadoop<span class="meta">@hadoop</span> hive]$ hadoop fs -mkdir -p <span class="regexp">/user/</span>hive/warehouse</span><br><span class="line"><span class="number">2018</span><span class="number">-12</span><span class="number">-06</span> <span class="number">16</span>:<span class="number">36</span>:<span class="number">10</span>,<span class="number">977</span> WARN util.<span class="string">NativeCodeLoader:</span> ... using builtin-java classes where applicable</span><br><span class="line">[hadoop<span class="meta">@hadoop</span> hive]$ hadoop fs -chmod <span class="number">777</span> <span class="regexp">/user/</span>hive/warehouse</span><br><span class="line"><span class="number">2018</span><span class="number">-12</span><span class="number">-06</span> <span class="number">16</span>:<span class="number">36</span>:<span class="number">38</span>,<span class="number">038</span> WARN util.<span class="string">NativeCodeLoader:</span> ... using builtin-java classes where applicable</span><br><span class="line">[hadoop<span class="meta">@hadoop</span> hive]$ hadoop fs -mkdir -p <span class="regexp">/tmp/</span>hive</span><br><span class="line"><span class="number">2018</span><span class="number">-12</span><span class="number">-06</span> <span class="number">16</span>:<span class="number">36</span>:<span class="number">46</span>,<span class="number">047</span> WARN util.<span class="string">NativeCodeLoader:</span> ... using builtin-java classes where applicable</span><br><span class="line">[hadoop<span class="meta">@hadoop</span> hive]$ hadoop fs -chmod <span class="number">777</span> <span class="regexp">/tmp/</span>hive</span><br><span class="line"><span class="number">2018</span><span class="number">-12</span><span class="number">-06</span> <span class="number">16</span>:<span class="number">36</span>:<span class="number">50</span>,<span class="number">335</span> WARN util.<span class="string">NativeCodeLoader:</span> ... using builtin-java classes where applicable</span><br><span class="line">[hadoop<span class="meta">@hadoop</span> hive]$ hadoop fs -ls <span class="regexp">/user/</span>hive/</span><br><span class="line"><span class="number">2018</span><span class="number">-12</span><span class="number">-06</span> <span class="number">16</span>:<span class="number">37</span>:<span class="number">00</span>,<span class="number">295</span> WARN util.<span class="string">NativeCodeLoader:</span> ... using builtin-java classes where applicable</span><br><span class="line">Found <span class="number">1</span> items</span><br><span class="line">drwxrwxrwx   - hadoop supergroup          <span class="number">0</span> <span class="number">2018</span><span class="number">-12</span><span class="number">-06</span> <span class="number">16</span>:<span class="number">36</span> <span class="regexp">/user/</span>hive/warehouse</span><br><span class="line">[hadoop<span class="meta">@hadoop</span> hive]$ hadoop fs -ls <span class="regexp">/tmp/</span></span><br><span class="line"><span class="number">2018</span><span class="number">-12</span><span class="number">-06</span> <span class="number">16</span>:<span class="number">37</span>:<span class="number">06</span>,<span class="number">519</span> WARN util.<span class="string">NativeCodeLoader:</span> ... using builtin-java classes where applicable</span><br><span class="line">Found <span class="number">3</span> items</span><br><span class="line">drwx------   - hadoop supergroup          <span class="number">0</span> <span class="number">2018</span><span class="number">-11</span><span class="number">-22</span> <span class="number">16</span>:<span class="number">05</span> <span class="regexp">/tmp/</span>hadoop-yarn</span><br><span class="line">drwxrwxrwx   - hadoop supergroup          <span class="number">0</span> <span class="number">2018</span><span class="number">-12</span><span class="number">-06</span> <span class="number">16</span>:<span class="number">36</span> <span class="regexp">/tmp/</span>hive</span><br><span class="line">drwxrwxrwt   - hadoop wheel               <span class="number">0</span> <span class="number">2018</span><span class="number">-11</span><span class="number">-22</span> <span class="number">16</span>:<span class="number">49</span> <span class="regexp">/tmp/</span>logs</span><br><span class="line">[hadoop<span class="meta">@hadoop</span> hive]$ mkdir -p <span class="regexp">~/hive/</span>tmp</span><br></pre></td></tr></table></figure></p>
<h2 id="三、启动-Hive"><a href="#三、启动-Hive" class="headerlink" title="三、启动 Hive"></a>三、启动 Hive</h2><h3 id="1-初始化数据库"><a href="#1-初始化数据库" class="headerlink" title="1. 初始化数据库"></a>1. 初始化数据库</h3><p>命令:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">schematool -initSchema -dbType mysql</span><br></pre></td></tr></table></figure></p>
<p>结果:<br><figure class="highlight groovy"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">[hadoop<span class="meta">@hadoop</span> hive]$ schematool -initSchema -dbType mysql</span><br><span class="line"><span class="string">SLF4J:</span> Class path contains multiple SLF4J bindings.</span><br><span class="line"><span class="string">SLF4J:</span> Found binding <span class="keyword">in</span> [<span class="string">jar:</span><span class="string">file:</span><span class="regexp">/home/</span>hadoop<span class="regexp">/hive/</span>lib<span class="regexp">/log4j-slf4j-impl-2.10.0.jar!/</span>org<span class="regexp">/slf4j/</span>impl/StaticLoggerBinder.<span class="keyword">class</span>]</span><br><span class="line"><span class="string">SLF4J:</span> Found binding <span class="keyword">in</span> [<span class="string">jar:</span><span class="string">file:</span><span class="regexp">/home/</span>hadoop<span class="regexp">/hadoop/</span>share<span class="regexp">/hadoop/</span>common<span class="regexp">/lib/</span>slf4j-log4j12<span class="number">-1.7</span><span class="number">.25</span>.jar!<span class="regexp">/org/</span>slf4j<span class="regexp">/impl/</span>StaticLoggerBinder.<span class="keyword">class</span>]</span><br><span class="line"><span class="string">SLF4J:</span> See <span class="string">http:</span><span class="comment">//www.slf4j.org/codes.html#multiple_bindings for an explanation.</span></span><br><span class="line"><span class="string">SLF4J:</span> Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]</span><br><span class="line">Metastore connection <span class="string">URL:</span>    <span class="string">jdbc:</span><span class="string">mysql:</span><span class="comment">//192.168.80.90:3306/hive?createDatabaseIfNotExist=true</span></span><br><span class="line">Metastore Connection <span class="string">Driver :</span>    com.mysql.jdbc.Driver</span><br><span class="line">Metastore connection <span class="string">User:</span>   root</span><br><span class="line">Starting metastore schema initialization to <span class="number">3.1</span><span class="number">.0</span></span><br><span class="line">Initialization script hive-schema<span class="number">-3.1</span><span class="number">.0</span>.mysql.sql</span><br><span class="line"></span><br><span class="line">...</span><br><span class="line"></span><br><span class="line">Initialization script completed</span><br><span class="line">schemaTool completed</span><br></pre></td></tr></table></figure></p>
<h3 id="2-启动并测试-Hive"><a href="#2-启动并测试-Hive" class="headerlink" title="2. 启动并测试 Hive"></a>2. 启动并测试 Hive</h3><p>命令:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hive</span><br><span class="line">hive&gt; show <span class="built_in">functions</span>;</span><br></pre></td></tr></table></figure></p>
<p>结果:<br><figure class="highlight groovy"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">[hadoop<span class="meta">@hadoop</span> hive]$ hive</span><br><span class="line"><span class="string">SLF4J:</span> Class path contains multiple SLF4J bindings.</span><br><span class="line"><span class="string">SLF4J:</span> Found binding <span class="keyword">in</span> [<span class="string">jar:</span><span class="string">file:</span><span class="regexp">/home/</span>hadoop<span class="regexp">/hive/</span>lib<span class="regexp">/log4j-slf4j-impl-2.10.0.jar!/</span>org<span class="regexp">/slf4j/</span>impl/StaticLoggerBinder.<span class="keyword">class</span>]</span><br><span class="line"><span class="string">SLF4J:</span> Found binding <span class="keyword">in</span> [<span class="string">jar:</span><span class="string">file:</span><span class="regexp">/home/</span>hadoop<span class="regexp">/hadoop/</span>share<span class="regexp">/hadoop/</span>common<span class="regexp">/lib/</span>slf4j-log4j12<span class="number">-1.7</span><span class="number">.25</span>.jar!<span class="regexp">/org/</span>slf4j<span class="regexp">/impl/</span>StaticLoggerBinder.<span class="keyword">class</span>]</span><br><span class="line"><span class="string">SLF4J:</span> See <span class="string">http:</span><span class="comment">//www.slf4j.org/codes.html#multiple_bindings for an explanation.</span></span><br><span class="line"><span class="string">SLF4J:</span> Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]</span><br><span class="line"><span class="string">which:</span> no hbase <span class="keyword">in</span> (<span class="regexp">/usr/</span>local<span class="regexp">/jdk1.8.0_181/</span><span class="string">bin:</span><span class="regexp">/usr/</span>local<span class="regexp">/sbin:/</span>usr<span class="regexp">/local/</span><span class="string">bin:</span><span class="regexp">/usr/</span><span class="string">sbin:</span><span class="regexp">/usr/</span><span class="string">bin:</span><span class="regexp">/root/</span><span class="string">bin:</span><span class="regexp">/home/</span>hadoop<span class="regexp">/hadoop/</span><span class="string">sbin:</span><span class="regexp">/home/</span>hadoop<span class="regexp">/hadoop/</span><span class="string">bin:</span><span class="regexp">/home/</span>hadoop<span class="regexp">/hadoop/</span><span class="string">sbin:</span><span class="regexp">/home/</span>hadoop<span class="regexp">/hadoop/</span><span class="string">bin:</span><span class="regexp">/home/</span>hadoop<span class="regexp">/hadoop/</span><span class="string">sbin:</span><span class="regexp">/home/</span>hadoop<span class="regexp">/hadoop/</span><span class="string">bin:</span><span class="regexp">/home/</span>hadoop<span class="regexp">/hive/</span>bin)</span><br><span class="line"><span class="string">SLF4J:</span> Class path contains multiple SLF4J bindings.</span><br><span class="line"><span class="string">SLF4J:</span> Found binding <span class="keyword">in</span> [<span class="string">jar:</span><span class="string">file:</span><span class="regexp">/home/</span>hadoop<span class="regexp">/hive/</span>lib<span class="regexp">/log4j-slf4j-impl-2.10.0.jar!/</span>org<span class="regexp">/slf4j/</span>impl/StaticLoggerBinder.<span class="keyword">class</span>]</span><br><span class="line"><span class="string">SLF4J:</span> Found binding <span class="keyword">in</span> [<span class="string">jar:</span><span class="string">file:</span><span class="regexp">/home/</span>hadoop<span class="regexp">/hadoop/</span>share<span class="regexp">/hadoop/</span>common<span class="regexp">/lib/</span>slf4j-log4j12<span class="number">-1.7</span><span class="number">.25</span>.jar!<span class="regexp">/org/</span>slf4j<span class="regexp">/impl/</span>StaticLoggerBinder.<span class="keyword">class</span>]</span><br><span class="line"><span class="string">SLF4J:</span> See <span class="string">http:</span><span class="comment">//www.slf4j.org/codes.html#multiple_bindings for an explanation.</span></span><br><span class="line"><span class="string">SLF4J:</span> Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]</span><br><span class="line">Hive Session ID = <span class="number">48</span>da2fa7<span class="number">-57</span>f6<span class="number">-4</span>dcc-a2e7<span class="number">-81991</span>fcceb94</span><br><span class="line"></span><br><span class="line">Logging initialized using configuration <span class="keyword">in</span> <span class="string">jar:</span><span class="string">file:</span><span class="regexp">/home/</span>hadoop<span class="regexp">/hive/</span>lib<span class="regexp">/hive-common-3.1.1.jar!/</span>hive-log4j2.properties <span class="string">Async:</span> <span class="literal">true</span></span><br><span class="line">Hive-on-MR is deprecated <span class="keyword">in</span> Hive <span class="number">2</span> and may not be available <span class="keyword">in</span> the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive <span class="number">1.</span>X releases.</span><br><span class="line">Hive Session ID = d0459c0a-d421<span class="number">-4062</span>-a6ef<span class="number">-3</span>a060e244791</span><br><span class="line">hive&gt; show functions;</span><br><span class="line">OK</span><br><span class="line">!</span><br><span class="line">!=</span><br><span class="line">$sum0</span><br><span class="line">%</span><br><span class="line">&amp;</span><br><span class="line"></span><br><span class="line">...</span><br><span class="line"></span><br><span class="line">|</span><br><span class="line">~</span><br><span class="line">Time <span class="string">taken:</span> <span class="number">1.601</span> seconds, <span class="string">Fetched:</span> <span class="number">289</span> row(s)</span><br></pre></td></tr></table></figure></p>
<p><strong><em>Hive 安装结束</em></strong></p>

            <!--[if lt IE 9]><script>document.createElement('audio');</script><![endif]-->
            <audio id="audio" loop="1" preload="auto" controls="controls" data-autoplay="false">
                <source type="audio/mpeg" src="">
            </audio>
            
                <ul id="audio-list" style="display:none">
                    
                        <li title='0' data-url='http://link.hhtjim.com/163/35032211.mp3'></li>
                    
                        <li title='1' data-url='http://link.hhtjim.com/163/41500546.mp3'></li>
                    
                        <li title='2' data-url='http://link.hhtjim.com/163/555557845.mp3'></li>
                    
                        <li title='3' data-url='http://link.hhtjim.com/163/493041272.mp3'></li>
                    
                        <li title='4' data-url='http://link.hhtjim.com/163/493041272.mp3'></li>
                    
                        <li title='5' data-url='http://link.hhtjim.com/163/409650440.mp3'></li>
                    
                        <li title='6' data-url='http://link.hhtjim.com/163/409654855.mp3'></li>
                    
                        <li title='7' data-url='http://link.hhtjim.com/163/407761545.mp3'></li>
                    
                        <li title='8' data-url='http://link.hhtjim.com/163/409654856.mp3'></li>
                    
                        <li title='9' data-url='http://link.hhtjim.com/163/466327445.mp3'></li>
                    
                        <li title='10' data-url='http://link.hhtjim.com/163/409654857.mp3'></li>
                    
                        <li title='11' data-url='http://link.hhtjim.com/163/405987145.mp3'></li>
                    
                        <li title='12' data-url='http://link.hhtjim.com/163/474945732.mp3'></li>
                    
                        <li title='13' data-url='http://link.hhtjim.com/163/409654858.mp3'></li>
                    
                        <li title='14' data-url='http://link.hhtjim.com/163/452578261.mp3'></li>
                    
                        <li title='15' data-url='http://link.hhtjim.com/163/409654859.mp3'></li>
                    
                        <li title='16' data-url='http://link.hhtjim.com/163/435307781.mp3'></li>
                    
                        <li title='17' data-url='http://link.hhtjim.com/163/477145631.mp3'></li>
                    
                        <li title='18' data-url='http://link.hhtjim.com/163/456175343.mp3'></li>
                    
                        <li title='19' data-url='http://link.hhtjim.com/163/409654860.mp3'></li>
                    
                        <li title='20' data-url='http://link.hhtjim.com/163/408250066.mp3'></li>
                    
                        <li title='21' data-url='http://link.hhtjim.com/163/537262197.mp3'></li>
                    
                        <li title='22' data-url='http://link.hhtjim.com/163/447978200.mp3'></li>
                    
                        <li title='23' data-url='http://link.hhtjim.com/163/439625573.mp3'></li>
                    
                        <li title='24' data-url='http://link.hhtjim.com/163/457840567.mp3'></li>
                    
                        <li title='25' data-url='http://link.hhtjim.com/163/452575951.mp3'></li>
                    
                        <li title='26' data-url='http://link.hhtjim.com/163/454966416.mp3'></li>
                    
                        <li title='27' data-url='http://link.hhtjim.com/163/419375942.mp3'></li>
                    
                        <li title='28' data-url='http://link.hhtjim.com/163/411988718.mp3'></li>
                    
                        <li title='29' data-url='http://link.hhtjim.com/163/418279656.mp3'></li>
                    
                        <li title='30' data-url='http://link.hhtjim.com/163/417594827.mp3'></li>
                    
                        <li title='31' data-url='http://link.hhtjim.com/163/423104116.mp3'></li>
                    
                        <li title='32' data-url='http://link.hhtjim.com/163/452577615.mp3'></li>
                    
                        <li title='33' data-url='http://link.hhtjim.com/163/436675327.mp3'></li>
                    
                        <li title='34' data-url='http://link.hhtjim.com/163/413074476.mp3'></li>
                    
                </ul>
            
        </div>
        
    <div id='gitalk-container' class="comment link"
        data-ae='false'
        data-ci='6f2ced5993cec2abfdc0'
        data-cs='53941abd6c61cb31c982bddf0394826699a4b9a7'
        data-r='YongJie-Xie.github.io'
        data-o='YongJie-Xie'
        data-a='YongJie-Xie'
        data-d='false'
    >查看评论</div>


    </div>
    
</div>


    </div>
</div>
</body>
<script src="//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js"></script>
<script src="//lib.baomitu.com/jquery/1.8.3/jquery.min.js"></script>
<script src="/js/plugin.js"></script>
<script src="/js/diaspora.js"></script>
<link rel="stylesheet" href="/photoswipe/photoswipe.css">
<link rel="stylesheet" href="/photoswipe/default-skin/default-skin.css">
<script src="/photoswipe/photoswipe.min.js"></script>
<script src="/photoswipe/photoswipe-ui-default.min.js"></script>

<!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">
    <!-- Background of PhotoSwipe. 
         It's a separate element as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>
    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">
        <!-- Container that holds slides. 
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>
        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">
            <div class="pswp__top-bar">
                <!--  Controls are self-explanatory. Order can be changed. -->
                <div class="pswp__counter"></div>
                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
                <button class="pswp__button pswp__button--share" title="Share"></button>
                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>
                <!-- Preloader demo http://codepen.io/dimsemenov/pen/yyBWoR -->
                <!-- element will get class pswp__preloader--active when preloader is running -->
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                      <div class="pswp__preloader__cut">
                        <div class="pswp__preloader__donut"></div>
                      </div>
                    </div>
                </div>
            </div>
            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div> 
            </div>
            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>
            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>
            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>
        </div>
    </div>
</div>




</html>